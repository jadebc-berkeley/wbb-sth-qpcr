---
title: "qPCR KK validation"
author: "Jade Benjamin-Chung"
date: "4/12/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Analysis of sensitivity and specificy using Bayesian Latent Class Models

#### Joint distribution of the results of a 2x2 table 
- $T_1^+$ is the number of individuals who tested positive by Kato-Katz; $T_1^-$ is the number of individuals who tested negative by Kato-Katz 
- $T_2^+$ is the number of individuals who tested positive by qPCR; $T_2^-$ is the number of individuals who tested negative by qPCR
- $X_{++}$ is the number of individuals who tested positive in both tests, 
- $X_{+-}$ is the number of individuals who tested positive by Kato-Katz and negative by qPCR, 
- and so on. 
- $\pi$ is the true prevalence in the population
- $Se_1$ is the true sensitivity of Kato-Katz in the population; $Se_2$ is the true sensitivity of qPCR in the population
- $Sp_1$ is the true specificity of Kato-Katz in the population; $Sp_2$ is the true specificity of qPCR in the population 

$(X_{++},X_{+-},X_{-+},X_{--}) \sim \text{Multi}(p_{++},p_{+-},p_{-+},p_{--},N_k)$

$p_{++}=P(T_i^+,T_j^+) = [Se_1Se_2+ cov(D_{12}^+)]\pi + [(1-Sp_1)(1-Sp_2) + cov(D_{12}^-)](1-\pi)$

$p_{+-}=P(T_i^+,T_j^-) = [Se_1(Se_2-1)- cov(D_{12}^+)]\pi + [(1-Sp_1)Sp_2 - cov(D_{12}^-)](1-\pi)$

$p_{-+}=P(T_i^-,T_j^+) = [(Se_1-1)Se_2- cov(D_{12}^+)]\pi + [Sp_1(1-Sp_2) - cov(D_{12}^-)](1-\pi)$

$p_{--}=P(T_i^-,T_j^-) = [(Se_1-1)(1-Se_2)+ cov(D_{12}^+)]\pi + [Sp_1Sp_2 - cov(D_{12}^-)](1-\pi)$

Conditional correlations between two test outcomes for infected individuals

$\rho_{D+} = \frac{covD^+}{\sqrt{Se_i(1-Se_i)Se_j(1-Se_j)}}$

Conditional correlations between two test outcomes for non-infected individuals

$\rho_{D-} = \frac{covD^-}{\sqrt{Sp_i(1-Sp_i)Sp_j(1-Sp_j)}}$

- $(Sp_1-1)(1-Sp_2)\leq cov(D_{12}^+)\leq \text{min}(Sp_1,Sp_2)-Sp_1Sp_2$
- $(Se_1-1)(1-Se_2)\leq cov(D_{12}^+)\leq \text{min}(Se_1,Se_2)-Se_1Se_2$
- Further assuming that the covariance is positive: 
- $0\leq cov(D_{12}^+)\leq \text{min}(Sp_1,Sp_2)-Sp_1Sp_2$
- $0\leq cov(D_{12}^+)\leq \text{min}(Se_1,Se_2)-Se_1Se_2$

#### Priors
- $\pi \sim \text{beta}(\alpha_\pi,\beta_\pi)$; assume $\alpha = \beta =1$
- $Se_j \sim \text{beta}(\alpha_{Se_j},\beta_{Se_j}); j = (1,2)$; assume $\alpha = \beta =1$
- $Sp_j \sim \text{beta}(\alpha_{Sp_j},\beta_{Sp_j}); j = (1,2)$; assume $\alpha = \beta =1$
<!-- - $cov(D_{12}^+) \sim \text{genbeta}(\alpha_{cov(D_{12}^+)},\beta_{cov(D_{12}^+)})$, where $u_{se}=\text{min}(Se_1,Se_2)-Se_1Se_2$ -->
<!-- - $cov(D_{12}^-) \sim \text{genbeta}(\alpha_{cov(D_{12}^-)},\beta_{cov(D_{12}^-)})$, where $u_{sp}=\text{min}(Sp_1,Sp_2)-Sp_1Sp_2$ -->
- $cov(D_{12}^+) \sim \text{unif}(\alpha_{cov(D_{12}^+)},\beta_{cov(D_{12}^+)})$, where $u_{se}=\text{min}(Se_1,Se_2)-Se_1Se_2$
- $cov(D_{12}^-) \sim \text{unif}(\alpha_{cov(D_{12}^-)},\beta_{cov(D_{12}^-)})$, where $u_{sp}=\text{min}(Sp_1,Sp_2)-Sp_1Sp_2$

#### Data
```{r results='hide', message=FALSE, warning=FALSE}
rm(list=ls())
library(nimble)
library(reshape2)
library(ggplot2)
load("~/Dropbox/WASH-B-STH-Add-on/TFGH/Data/RData/qdata.RData")

```

```{r , echo=TRUE}
# define data for hookworm
hdata=qdata[!is.na(qdata$positive.Hw) & !is.na(qdata$hwkk),]
hw.x11=nrow(hdata[hdata$positive.Hw==1 & hdata$hwkk==1,])
hw.x10=nrow(hdata[hdata$positive.Hw==0 & hdata$hwkk==1,])
hw.x01=nrow(hdata[hdata$positive.Hw==1 & hdata$hwkk==0,])
hw.x00=nrow(hdata[hdata$positive.Hw==0 & hdata$hwkk==0,])
hw.n=sum(hw.x11,hw.x10,hw.x01,hw.x00)

hw.data=list(n=hw.n, x=c(hw.x11, hw.x10, hw.x01, hw.x00))
hw.data$x
```

#### Define Model
The following code chunk uses WinBUGS syntax to define the latent class model. 

```{r , echo=TRUE}
lca.hw <- nimbleCode({
  # stochastic node
  x[1:4] ~ dmulti(p[1:4], n) 
  
  # deterministic nodes
  p[1] <- pi*(Se1*Se2+covDp) + (1-pi)*((1-Sp1)*(1-Sp2)+covDn)
  p[2] <- pi*(Se1*(1-Se2)-covDp) + (1-pi)*((1-Sp1)*Sp2-covDn)
  p[3] <- pi*((1-Se1)*Se2-covDp) + (1-pi)*(Sp1*(1-Sp2)-covDn)
  p[4] <- pi*((1-Se1)*(1-Se2)+covDp) + (1-pi)*(Sp1*Sp2+covDn)
  
  us <- min(Se1,Se2) - Se1*Se2
  uc <- min(Sp1,Sp2) - Sp1*Sp2
  
  # prior values
  pi ~ dbeta(1,1) 
  Se1 ~ dbeta(1,1) 
  Sp1 ~ dbeta(1,1) 
  Se2 ~ dbeta(1,1) 
  Sp2 ~ dbeta(1,1) 
  
  covDn ~ dunif(0, uc)
  covDp ~ dunif(0, us)
  rhoD <- covDp / sqrt(Se1*(1-Se1)*Se2*(1-Se2))
  rhoDc <- covDn / sqrt(Sp1*(1-Sp1)*Sp2*(1-Sp2))
})
```

I chose initial values as follows:

- `pi`: prevalence of hookworm by qPCR in our study
- `Se1`, `Sp1`: estimates for Kato-Katz from Nikolay et al. 
- `Se2`, `Sp2`: estimates from Easton et al. 
- `covDp`, `covDn`: I randomly sampled from the prior distribution defined above. 
- `p`: For the probability of each count, I calculated the expected value using the assumptions defined above. 
- `rhoD`, `rhoDc`: I arbitrarily chose 0.5, but am open to better ideas!

```{r , echo=TRUE}
# define initial values
set.seed(123)
hw.inits=list(pi=0.22, Se1=0.526, Se2=0.98, Sp1=0.986, Sp2=0.97, 
              rhoD=0.5, rhoDc=0.5, 
              p=c(0.526*0.22+0.98*0.22, 
                  0.526*0.22+0.97*(1-0.22), 
                  0.986*(1-0.22)+0.98*0.22, 
                  0.986*(1-0.22)+0.97*(1-0.22)), 
              covDp=runif(1,min=0,max=0.526-(0.526*0.98)),
              covDn=runif(1,min=0,max=0.97-(0.986*0.97)))
```

#### Display DAG

```{r , echo=TRUE, message=FALSE, fig.width=8, fig.height=8}
# process BUGS model code
lca.model.hw <- nimbleModel(lca.hw, inits=hw.inits, data=hw.data)

# plot DAG
lca.model.hw$plotGraph()
```

#### Compile and configure Monte Carlo Markov Chain (MCMC) 
Below I define the features of the MCMC model. The default sampling is Metropolis Hastings. WinBUGS (and thus all papers on this subject) uses Gibbs sampling, which is a special case of Metropolis Hastings. I'm not totally sure if this is different from Gibbs sampling in WinBUGS. 

```{r , echo=TRUE}
c.lca.model.hw=compileNimble(lca.model.hw)
monitors=c("pi","Se1","Se2","Sp1","Sp2","rhoD", "rhoDc")
thin=100
lca.hw.Conf <- configureMCMC(lca.model.hw,
      monitors=monitors,
      thin=thin, print = TRUE)
hw.MCMC <- buildMCMC(lca.hw.Conf, enableWAIC = TRUE)
C.hw.MCMC <- compileNimble(hw.MCMC, project=lca.model.hw)
```


#### Run MCMC
Next I run MCMC with 10,000 iterations and four chains. I specify different initial values for each chain. The values for chains 2-3 are completely arbitrary. I need to investigate whether they need to be more thoughtful (probably).

```{r , echo=TRUE}
niter=1000000

# specify initial values for each chain
hw.inits=list(list(pi=0.22, Se1=0.526, Se2=0.98, Sp1=0.986, Sp2=0.97,
                   rhoD=0.5, rhoDc=0.5,
                   p=c(0.526*0.22+0.98*0.22,
                       0.526*0.22+0.97*(1-0.22),
                       0.986*(1-0.22)+0.98*0.22,
                       0.986*(1-0.22)+0.97*(1-0.22))),
              list(pi=0.5, Se1=0.5, Se2=0.5, Sp1=0.5, Sp2=0.5,
                   rhoD=0.5, rhoDc=0.5,
                   p=c(0.5,0.5,0.5,0.5)),
              list(pi=0.3, Se1=0.3, Se2=0.3, Sp1=0.3, Sp2=0.3,
                   rhoD=0.3, rhoDc=0.3,
                   p=c(0.3,0.3,0.3,0.3)),
              list(pi=0.4, Se1=0.4, Se2=0.4, Sp1=0.4, Sp2=0.4,
                   rhoD=0.4, rhoDc=0.4,
                   p=c(0.4,0.4,0.4,0.4)))
set.seed(12345)
mcmc.hw.out <- runMCMC(C.hw.MCMC, niter = niter, nchains = 4, inits=hw.inits)
```


```{r , echo=TRUE}
samples.hw.f=as.data.frame(do.call(rbind,mcmc.hw.out))
rows=niter/thin
samples.hw.f$chain=as.factor(c(rep(1,rows),rep(2,rows),rep(3,rows),rep(4,rows)))

# convert samples to long format for plotting
samples.hw.l=melt(samples.hw.f,id.vars=c("chain"))

# plot history of each parameter
numMonitors=7
xseq=rep(rep(seq(1,niter),numMonitors),4)
```

#### Plot the parameter estimates for each MCMC iteration
For each parameter with 10,000 iterations convergence isn't great. 
```{r , echo=TRUE, fig.width=9, fig.height=7}
ggplot(samples.hw.l, aes(x=xseq,y=value,color=chain))+
  geom_line()+facet_wrap(~variable, scales="free", ncol=2)+theme_bw()+
  xlab("Iteration")+ylab("Parameter estimate")
```

#### Plot the density of parameter estimates from MCMC
```{r , echo=TRUE, fig.width=9, fig.height=7}
ggplot(samples.hw.l, aes(x=value))+geom_density(aes(col=chain))+
  facet_wrap(~variable, scales="free", ncol=2)+theme_bw()+
  xlab("Kernal density")+xlab("Parameter estimate")
```

#### Plot autocorrelation for each parameter
The plots below show the correlation between samples from different iterations. Ideally correlation would decrease across the x-axis, but that's not what's happening here. I'm not sure what to do about this other than "thinning" which is the practice of increasing the number of iterations and save every ith iteration. This seems like a bandaid solution.

```{r , echo=TRUE, fig.width=9, fig.height=3}
par(mfrow = c(1, 5), mai = c(.6, .4, .1, .2))
acf(samples.hw.f[, "pi"])
acf(samples.hw.f[, "Se1"]) 
acf(samples.hw.f[, "Se2"]) 
acf(samples.hw.f[, "Sp1"]) 
acf(samples.hw.f[, "Sp2"]) 
```



